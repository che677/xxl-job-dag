spring:
  kafka:
    bootstrap-servers: master:9092,master:9093
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      # 生产者每个批次最多提交多大的数据（默认16k）
      batch-size: 16384
      # 生产者一端总的可用发送缓冲区大小，为32MB
      buffer-memory: 33554432
      compression-type: snappy
      properties:
        # request.timeout.ms 在发送数据时等待服务器返回响应的时间
        request:
          timeout:
            ms: 3000
        # 每一批次发送的等待时间
        linger:
          ms: 100
        # retry.backoff.ms  每次重试之间的时间间隔，默认是100ms，这里配置50ms
        retry:
          backoff:
            ms: 100
      acks: all
      retries: 3
    consumer:
      concurrency: 3  # 监听器的线程数
      maxpollrecordsconfig: 500 # 每批次获取的数据条数
      # 消费组ID
      group-id: defaultConsumerGroup
      # 如果在当前kafka中找不到当前offset，就读取最早的
      auto-offset-reset: earliest
      # 自动提交偏移量
      enable-auto-commit: false
      # offset自动提交的时间间隔
      auto-commit-interval: 1000
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    listener:
      missing-topics-fatal: false
      ack-mode: manual_immediate
      concurrency: 3