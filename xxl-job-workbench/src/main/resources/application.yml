server:
  port: 12809
  servlet:
    context-path: /workbench

mybatis:
  mapper-locations: classpath:mapper/*.xml
  type-aliases-package: com.xxl.job.core.biz.model

spring:
  datasource:
    master:
      url: jdbc:mysql://localhost:3306/workbench?characterEncoding=UTF-8&autoReconnect=true&zeroDateTimeBehavior=convertToNull&useUnicode=true&serverTimezone=GMT
      username: root
      password: 123456
      driverClassName: com.mysql.cj.jdbc.Driver
    slave1:
      url: jdbc:mysql://localhost:3307/workbench?characterEncoding=UTF-8&autoReconnect=true&zeroDateTimeBehavior=convertToNull&useUnicode=true&serverTimezone=GMT
      username: root
      password: 123456
      driverClassName: com.mysql.cj.jdbc.Driver
    slave2:
      url: jdbc:mysql://localhost:3308/workbench?characterEncoding=UTF-8&autoReconnect=true&zeroDateTimeBehavior=convertToNull&useUnicode=true&serverTimezone=GMT
      username: root
      password: 123456
      driverClassName: com.mysql.cj.jdbc.Driver
    hikari:
      leak-detection-threshold: 2000
  kafka:
    bootstrap-servers: master:9092,master:9093
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      # 生产者每个批次最多提交多大的数据（默认16k）
      batch-size: 16384
      # 生产者一端总的可用发送缓冲区大小，为32MB
      buffer-memory: 33554432
      compression-type: snappy
      properties:
      # request.timeout.ms 在发送数据时等待服务器返回响应的时间
        request:
          timeout:
            ms: 1000
        # 每一批次发送的等待时间
        linger:
          ms: 100
        # retry.backoff.ms  每次重试之间的时间间隔，默认是100ms，这里配置50ms
        retry:
          backoff:
            ms: 100
      acks: all
      retries: 3
    consumer:
      concurrency: 3  # 监听器的线程数
      maxpollrecordsconfig: 500 # 每批次获取的数据条数
      # 消费组ID
      group-id: defaultConsumerGroup
      # 如果在当前kafka中找不到当前offset，就读取最早的
      auto-offset-reset: earliest
      # 自动提交偏移量
      enable-auto-commit: false
      # offset自动提交的时间间隔
      auto-commit-interval: 1000
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    listener:
      missing-topics-fatal: false
      ack-mode: manual_immediate
      concurrency: 3
dubbo:
  protocol:
    name: dubbo
    port: 20881
  application:
    name: demo-consumer # 消息者名字
  registry:
    address: zookeeper://master:2181?backup=master:2181
  consumer:
    timeout: 1000